{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "CNN",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brian Lee - Twitter Spam Detection Through CNN Text Classifier\n",
        "\n",
        "##Reference: [A deep learning model for Twitter spam detection](https://www.sciencedirect.com/science/article/pii/S2468696420300203)"
      ],
      "metadata": {
        "id": "NUTY8WR55pSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PYTORCH\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Other ML Tools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
        "\n",
        "# Basic Libraries\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import random\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:17.247123Z",
          "iopub.execute_input": "2022-05-01T20:20:17.247437Z",
          "iopub.status.idle": "2022-05-01T20:20:20.213138Z",
          "shell.execute_reply.started": "2022-05-01T20:20:17.247350Z",
          "shell.execute_reply": "2022-05-01T20:20:20.212325Z"
        },
        "trusted": true,
        "id": "ZCQpxmnaTHRP"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:20.216919Z",
          "iopub.execute_input": "2022-05-01T20:20:20.217119Z",
          "iopub.status.idle": "2022-05-01T20:20:20.348922Z",
          "shell.execute_reply.started": "2022-05-01T20:20:20.217094Z",
          "shell.execute_reply": "2022-05-01T20:20:20.348211Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFH3BSpWTHRR",
        "outputId": "daf47b32-dd53-420c-c91e-812c719517c9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find Hyperlinks in string"
      ],
      "metadata": {
        "id": "5Qg0c1RxTHRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findUrl(string):\n",
        "    # findall() has been used with valid conditions for urls in string\n",
        "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
        "    found = re.search(regex, string)\n",
        "    return found"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:20.350397Z",
          "iopub.execute_input": "2022-05-01T20:20:20.350854Z",
          "iopub.status.idle": "2022-05-01T20:20:20.357630Z",
          "shell.execute_reply.started": "2022-05-01T20:20:20.350814Z",
          "shell.execute_reply": "2022-05-01T20:20:20.356880Z"
        },
        "trusted": true,
        "id": "Axy7jZ3PTHRT"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader / Tokenizer"
      ],
      "metadata": {
        "id": "GLZdd0L-THRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "Y = list((train_data['Type'] == 'Quality').astype(int))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "hashtag = True\n",
        "wordcount = defaultdict(int)\n",
        "vocab_size = 500\n",
        "\n",
        "lines = []\n",
        "maxlen = 0\n",
        "for data in train_data['Tweet']:\n",
        "\n",
        "    line = ['<START>']\n",
        "\n",
        "    tokens = tokenizer.tokenize(data.lower())\n",
        "\n",
        "    for token in tokens:\n",
        "        url = findUrl(token)\n",
        "        if url:\n",
        "            line.append('<URL>')\n",
        "            wordcount['<URL>'] += 1\n",
        "        elif token[0] == '#':\n",
        "            if hashtag:\n",
        "                line.append(token)\n",
        "                wordcount[token] += 1\n",
        "            else:\n",
        "                line.append('<HASH>')\n",
        "                wordcount['<HASH>'] += 1\n",
        "        else:\n",
        "            more_words = word_tokenize(token)\n",
        "            for w in more_words:\n",
        "                line.append(w)\n",
        "                wordcount[w] += 1\n",
        "\n",
        "    line.append('<END>')\n",
        "    maxlen = max(maxlen, len(line))\n",
        "    lines.append(line)\n",
        "\n",
        "wordcount['<START>'] = len(train_data['Tweet'])\n",
        "wordcount['<END>'] = len(train_data['Tweet'])\n",
        "\n",
        "sorted_wordcounts = sorted(wordcount.items(), key = lambda item: item[1], reverse=True)\n",
        "\n",
        "word2ind = {}\n",
        "ind2word = {}\n",
        "\n",
        "ind = 1\n",
        "for k, v in sorted_wordcounts[:vocab_size - 1]:\n",
        "    word2ind[k] = ind\n",
        "    ind2word[ind] = k\n",
        "    ind += 1\n",
        "\n",
        "for k, v in sorted_wordcounts[vocab_size - 1:]:\n",
        "    word2ind[k] = vocab_size\n",
        "    ind2word[vocab_size - 1] = '<UKN>'\n",
        "\n",
        "X = []\n",
        "\n",
        "for line in lines:\n",
        "    ind_line = []\n",
        "    for word in line:\n",
        "        ind_line.append(word2ind[word])\n",
        "    \n",
        "    if len(ind_line) < maxlen:\n",
        "        ind_line += [0] * (maxlen - len(ind_line))\n",
        "    \n",
        "    X.append(ind_line)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:20.358714Z",
          "iopub.execute_input": "2022-05-01T20:20:20.359203Z",
          "iopub.status.idle": "2022-05-01T20:20:33.848366Z",
          "shell.execute_reply.started": "2022-05-01T20:20:20.359162Z",
          "shell.execute_reply": "2022-05-01T20:20:33.847654Z"
        },
        "trusted": true,
        "id": "UB7zsMLSTHRU"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(X, Y):\n",
        "    shuffled_X = []\n",
        "    shuffled_Y = []\n",
        "    indices = list(range(len(X)))\n",
        "    random.shuffle(indices)\n",
        "    for i in indices:\n",
        "        shuffled_X.append(X[i])\n",
        "        shuffled_Y.append(Y[i])\n",
        "    return (shuffled_X, shuffled_Y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:33.857848Z",
          "iopub.execute_input": "2022-05-01T20:20:33.858249Z",
          "iopub.status.idle": "2022-05-01T20:20:33.866529Z",
          "shell.execute_reply.started": "2022-05-01T20:20:33.858212Z",
          "shell.execute_reply": "2022-05-01T20:20:33.865852Z"
        },
        "trusted": true,
        "id": "Zn1Vo7XUTHRV"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, Y, cnn):\n",
        "    optimizer = Adam(cnn.parameters(), lr = 0.01)\n",
        "    loss_f = nn.NLLLoss()\n",
        "    n_epochs = 10\n",
        "    batchSize = 10\n",
        "    for epoch in range(n_epochs):\n",
        "        cnn.train()\n",
        "        totalLoss = 0.0\n",
        "\n",
        "        shuffled_X, shuffled_Y = shuffle_data(X, Y)\n",
        "        X_train, Y_train = torch.tensor(shuffled_X, device = device), torch.tensor(shuffled_Y, dtype = float, device = device)\n",
        "\n",
        "        for batch in range(len(X_train)//10 + 1):\n",
        "            cnn.zero_grad()\n",
        "            x = X_train[batch*batchSize: (batch + 1)*batchSize]\n",
        "            y = Y_train[batch*batchSize: (batch + 1)*batchSize]\n",
        "            y = y.to(dtype=int)\n",
        "            output = cnn(x)\n",
        "            loss = loss_f(output, y)\n",
        "            totalLoss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"total loss is: \", totalLoss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:20:33.868905Z",
          "iopub.execute_input": "2022-05-01T20:20:33.870220Z",
          "iopub.status.idle": "2022-05-01T20:20:33.879525Z",
          "shell.execute_reply.started": "2022-05-01T20:20:33.870189Z",
          "shell.execute_reply": "2022-05-01T20:20:33.878764Z"
        },
        "trusted": true,
        "id": "ohISA5m7THRW"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, NUM_CLASSES=2, VOCAB_SIZE=vocab_size, DIM_EMB=200):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.Embedding = nn.Embedding(VOCAB_SIZE + 1 , DIM_EMB)\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=DIM_EMB,\n",
        "                      out_channels=2,\n",
        "                      kernel_size=ks)\n",
        "            for ks in range(2, 5)\n",
        "        ])\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.MaxPool = nn.MaxPool1d\n",
        "        self.Dropout = nn.Dropout()\n",
        "        self.Linear = nn.Linear(6, NUM_CLASSES)\n",
        "        self.LogSoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        E = self.Embedding(X).permute(0, 2, 1)\n",
        "        R = [self.ReLU(conv1d(E)) for conv1d in self.conv1d_list]\n",
        "        M = [self.MaxPool(kernel_size=r.shape[2])(r) for r in R]\n",
        "        C = torch.cat([m.squeeze(dim=2) for m in M], dim = 1)\n",
        "        L = self.Linear(C)\n",
        "        X = self.LogSoftmax(L)\n",
        "        return X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:23:20.691969Z",
          "iopub.execute_input": "2022-05-01T20:23:20.692429Z",
          "iopub.status.idle": "2022-05-01T20:23:20.702124Z",
          "shell.execute_reply.started": "2022-05-01T20:23:20.692394Z",
          "shell.execute_reply": "2022-05-01T20:23:20.701462Z"
        },
        "trusted": true,
        "id": "hAkz2dTxTHRW"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN().to(device)\n",
        "train(X[1000:], Y[1000:], cnn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-01T20:23:22.446450Z",
          "iopub.execute_input": "2022-05-01T20:23:22.447311Z",
          "iopub.status.idle": "2022-05-01T20:23:22.500877Z",
          "shell.execute_reply.started": "2022-05-01T20:23:22.447271Z",
          "shell.execute_reply": "2022-05-01T20:23:22.499896Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAaj3giiTHRX",
        "outputId": "dd5283a8-7a64-463f-db91-f1ae5e19e935"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total loss is:  525.3924923986197\n",
            "total loss is:  444.56662080809474\n",
            "total loss is:  432.5548881990835\n",
            "total loss is:  415.68563915230334\n",
            "total loss is:  413.3081519016996\n",
            "total loss is:  395.66704229824245\n",
            "total loss is:  388.2934821471572\n",
            "total loss is:  381.0469605503604\n",
            "total loss is:  388.5188425361994\n",
            "total loss is:  386.07888509356417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_X, test_Y):\n",
        "\n",
        "  input = torch.tensor(test_X, dtype=int, device = device)\n",
        "  model.eval()\n",
        "  y_pred = model(input).squeeze().argmax(dim=1).tolist()\n",
        "  y_true = test_Y\n",
        "  print(classification_report(y_true, y_pred, labels=[1, 0], digits = 4))\n",
        "\n",
        "evaluate(cnn, X[:1000], Y[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8pb47Ery-ur",
        "outputId": "f41ed5d0-d00b-4ecb-e9a1-6fdb64dfc4a7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8494    0.7186    0.7786       526\n",
            "           0     0.7333    0.8586    0.7911       474\n",
            "\n",
            "    accuracy                         0.7850      1000\n",
            "   macro avg     0.7914    0.7886    0.7848      1000\n",
            "weighted avg     0.7944    0.7850    0.7845      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p_pd6nZRy_bN"
      },
      "execution_count": 146,
      "outputs": []
    }
  ]
}