{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/animesharma3/Spam-Detector-BERT-Pytorch-Transformers-Hugging-Face-NLP-State-of-the-Art-Model./blob/main/Spam_Detector_%7C_BERT_%7C_Pytorch_%7C_Transformers_%7C_Hugging_Face_%7C_NLP_%7C_State_of_the_Art_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Installing and Importing Dependencies","metadata":{"id":"-INlSfgHgBzA"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"Qc5FU0v82Avh","outputId":"700345d8-d50c-4d23-8a1c-c7fea2eaa049","execution":{"iopub.status.busy":"2022-05-04T04:08:55.146036Z","iopub.execute_input":"2022-05-04T04:08:55.146357Z","iopub.status.idle":"2022-05-04T04:09:05.471882Z","shell.execute_reply.started":"2022-05-04T04:08:55.146276Z","shell.execute_reply":"2022-05-04T04:09:05.471018Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\n\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup, BertConfig\nfrom transformers.models.bert.modeling_bert import BertEmbeddings\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"id":"uBT2n_h2wuRC","execution":{"iopub.status.busy":"2022-05-04T04:09:05.474918Z","iopub.execute_input":"2022-05-04T04:09:05.475144Z","iopub.status.idle":"2022-05-04T04:09:12.460361Z","shell.execute_reply.started":"2022-05-04T04:09:05.475117Z","shell.execute_reply":"2022-05-04T04:09:12.459647Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Setting Variables","metadata":{"id":"RFGN_FrkgLj2"}},{"cell_type":"code","source":"PRE_TRAINED_MODEL_NAME = 'prajjwal1/bert-tiny'\ndevice = 'cuda'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\nEPOCHS=10\nMAX_LEN=512\nBATCH_SIZE=16\n","metadata":{"id":"y9nJO_X24fLB","execution":{"iopub.status.busy":"2022-05-04T04:09:12.461570Z","iopub.execute_input":"2022-05-04T04:09:12.463619Z","iopub.status.idle":"2022-05-04T04:09:16.190266Z","shell.execute_reply.started":"2022-05-04T04:09:12.463588Z","shell.execute_reply":"2022-05-04T04:09:16.189559Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Reading and Preprocessing Data","metadata":{"id":"ietiWNbYgR-i"}},{"cell_type":"code","source":"# df = pd.read_csv('https://raw.githubusercontent.com/animesharma3/SPAM-SMS-Detection/master/spam_sms_collection.csv')[['msg', 'spam']]\ndf = pd.read_csv('../input/twitter-spam-dataset/train.csv')[['Tweet', 'Type']]\ndf['msg'] = df['Tweet']\ndf['spam'] = (1 * (df['Type'] == 'Quality'))","metadata":{"id":"iQ6uw08ox3XY","outputId":"81e691d5-a314-457e-e100-1f7b353aafe7","execution":{"iopub.status.busy":"2022-05-04T04:09:16.193248Z","iopub.execute_input":"2022-05-04T04:09:16.193520Z","iopub.status.idle":"2022-05-04T04:09:16.271984Z","shell.execute_reply.started":"2022-05-04T04:09:16.193487Z","shell.execute_reply":"2022-05-04T04:09:16.271358Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"id":"5Vz5fBKRx9c_","outputId":"bb1e6bd7-3a61-4600-f649-2264544482ac","execution":{"iopub.status.busy":"2022-05-04T04:09:16.273112Z","iopub.execute_input":"2022-05-04T04:09:16.273338Z","iopub.status.idle":"2022-05-04T04:09:16.283208Z","shell.execute_reply.started":"2022-05-04T04:09:16.273304Z","shell.execute_reply":"2022-05-04T04:09:16.282488Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class SpamDataset(Dataset):\n    def __init__(self, spam, msgs, tokenizer, max_len):\n        self.msgs = msgs\n        self.spam = spam\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.msgs)\n\n    def __getitem__(self, i):\n        msg = str(self.msgs[i])\n        spam = self.spam[i]\n\n        encoding = self.tokenizer.encode_plus(\n            msg, \n            add_special_tokens=True,\n            max_length=self.max_len,\n            truncation=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'msg': msg,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'spam': torch.tensor(spam, dtype=torch.long)\n        }","metadata":{"id":"78kRG9Qkzi3W","execution":{"iopub.status.busy":"2022-05-04T04:09:16.284412Z","iopub.execute_input":"2022-05-04T04:09:16.285063Z","iopub.status.idle":"2022-05-04T04:09:16.292581Z","shell.execute_reply.started":"2022-05-04T04:09:16.285026Z","shell.execute_reply":"2022-05-04T04:09:16.291846Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_data_loader(df, tokenizer, max_len, batch_size):\n    ds = SpamDataset(\n        spam=df['spam'].to_numpy(),\n        msgs=df['msg'].to_numpy(),\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n\n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        num_workers=4\n    )","metadata":{"id":"0RK3hJDCzS73","execution":{"iopub.status.busy":"2022-05-04T04:09:16.293650Z","iopub.execute_input":"2022-05-04T04:09:16.294298Z","iopub.status.idle":"2022-05-04T04:09:16.303619Z","shell.execute_reply.started":"2022-05-04T04:09:16.294262Z","shell.execute_reply":"2022-05-04T04:09:16.302951Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = tts(\n    df,\n    test_size=0.2,\n    random_state=42,\n    shuffle=True,\n)\ndf_val, _ = tts(\n    df,\n    test_size=0.5,\n    random_state=42,\n    shuffle=True,\n)\ndf_train.shape, df_test.shape, df_val.shape\n","metadata":{"id":"VsfQUZPQyPLl","outputId":"20e25e51-2b42-49fb-e72e-52e010e21edb","execution":{"iopub.status.busy":"2022-05-04T04:09:16.305027Z","iopub.execute_input":"2022-05-04T04:09:16.305558Z","iopub.status.idle":"2022-05-04T04:09:16.320727Z","shell.execute_reply.started":"2022-05-04T04:09:16.305514Z","shell.execute_reply":"2022-05-04T04:09:16.320000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)","metadata":{"id":"rSd4b1Mx6OR4","execution":{"iopub.status.busy":"2022-05-04T04:09:16.321935Z","iopub.execute_input":"2022-05-04T04:09:16.322173Z","iopub.status.idle":"2022-05-04T04:09:16.327662Z","shell.execute_reply.started":"2022-05-04T04:09:16.322141Z","shell.execute_reply":"2022-05-04T04:09:16.326965Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"d = next(iter(train_data_loader))\nd.keys()","metadata":{"id":"RXmAJbDr6fVe","outputId":"78dde2e0-9c37-4864-c49c-3a02ff8a7084","execution":{"iopub.status.busy":"2022-05-04T04:09:16.331230Z","iopub.execute_input":"2022-05-04T04:09:16.331421Z","iopub.status.idle":"2022-05-04T04:09:16.589802Z","shell.execute_reply.started":"2022-05-04T04:09:16.331398Z","shell.execute_reply":"2022-05-04T04:09:16.589072Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(d['input_ids'].shape, d['attention_mask'].shape, d['spam'].shape)\nprint(d['input_ids'])\n","metadata":{"id":"awSWUDUd6xoI","outputId":"eccd27c9-c0af-4e40-b5ef-b932fd9c3782","execution":{"iopub.status.busy":"2022-05-04T04:09:16.592577Z","iopub.execute_input":"2022-05-04T04:09:16.592782Z","iopub.status.idle":"2022-05-04T04:09:16.606799Z","shell.execute_reply.started":"2022-05-04T04:09:16.592756Z","shell.execute_reply":"2022-05-04T04:09:16.605836Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{"id":"HDxtdPbJgY5n"}},{"cell_type":"code","source":"from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nclass CNN(nn.Module):\n    def __init__(self, NUM_CLASSES = 2, DIM_EMB = MAX_LEN):\n        super(CNN, self).__init__()\n        self.Embedding = self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME).get_input_embeddings()\n        print(\"EMBEDDING\", self.Embedding)\n        self.conv1d_list = nn.ModuleList([\n            nn.Conv1d(in_channels=DIM_EMB,\n                      out_channels=2,\n                      kernel_size=ks)\n            for ks in range(2, 5)\n        ])\n        self.ReLU = nn.ReLU()\n        self.MaxPool = nn.MaxPool1d\n        self.Dropout = nn.Dropout()\n        self.Linear = nn.Linear(6, NUM_CLASSES)\n        self.LogSoftmax = nn.LogSoftmax(dim=1)\n        \n#         # self.embedding = nn.Embedding(max_len, max_len, padding_idx=0)\n#         self.lstm = nn.LSTM(input_size=128,\n#                             hidden_size=h_dim,\n#                             num_layers=lstm_layers,\n#                             batch_first=True,\n#                             bidirectional=True)\n#         self.fc = nn.Linear(2 * lstm_layers * h_dim, 2)\n#         self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_ids, attention_mask):\n#         N, L = input_ids.shape\n#         embedding_output = self.embeddings(input_ids)\n#         out, (h, c) = self.lstm(embedding_output)\n#         h = h.permute(1, 0, 2).resize(N, 2 * self.lstm_layers * self.h_dim)\n\n#         return torch.sigmoid(self.fc(h))\n\n#         X = X.to(dtype=int)\n        E = self.Embedding(input_ids)\n        # print(\"E\", E.shape)\n        R = [self.ReLU(conv1d(E)) for conv1d in self.conv1d_list]\n        # print(\"R\")\n        M = [self.MaxPool(kernel_size=r.shape[2])(r) for r in R]\n        # print(\"M\")\n        C = torch.cat([m.squeeze(dim=2) for m in M], dim = 1)\n        # print(\"C\")\n        L = self.Linear(C)\n        # print(\"L\")\n        X = self.LogSoftmax(L)\n        # print(\"X\")\n        return X\n\nmodel = CNN().to(device)","metadata":{"id":"YXy7V_kJ8g7H","execution":{"iopub.status.busy":"2022-05-04T04:09:16.608589Z","iopub.execute_input":"2022-05-04T04:09:16.608838Z","iopub.status.idle":"2022-05-04T04:09:23.829661Z","shell.execute_reply.started":"2022-05-04T04:09:16.608805Z","shell.execute_reply":"2022-05-04T04:09:23.828853Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T04:09:23.831006Z","iopub.execute_input":"2022-05-04T04:09:23.831262Z","iopub.status.idle":"2022-05-04T04:09:23.835253Z","shell.execute_reply.started":"2022-05-04T04:09:23.831227Z","shell.execute_reply":"2022-05-04T04:09:23.834601Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# model = CNN().to(device)\n","metadata":{"id":"_1uiooAZPru3","execution":{"iopub.status.busy":"2022-05-04T04:09:23.836747Z","iopub.execute_input":"2022-05-04T04:09:23.837221Z","iopub.status.idle":"2022-05-04T04:09:23.847516Z","shell.execute_reply.started":"2022-05-04T04:09:23.837180Z","shell.execute_reply":"2022-05-04T04:09:23.846782Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Loss, Optimizer and Scheduler","metadata":{"id":"2IlXMoLageQl"}},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-3, correct_bias=False)\n\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.NLLLoss().to(device)","metadata":{"id":"06B3UYiEP2N8","execution":{"iopub.status.busy":"2022-05-04T04:09:23.848784Z","iopub.execute_input":"2022-05-04T04:09:23.849366Z","iopub.status.idle":"2022-05-04T04:09:23.861911Z","shell.execute_reply.started":"2022-05-04T04:09:23.849306Z","shell.execute_reply":"2022-05-04T04:09:23.861118Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# input_ids = d['input_ids'].to(device)\n# attention_mask = d['attention_mask'].to(device)\n# targets = d['spam'].to(device)\n\n# outputs = model(\n#     input_ids=input_ids,\n#     attention_mask=attention_mask\n# )\n# loss = loss_fn(outputs, targets)\n# loss","metadata":{"id":"Hb7uxa1LUlVO","execution":{"iopub.status.busy":"2022-05-04T04:09:23.863144Z","iopub.execute_input":"2022-05-04T04:09:23.863980Z","iopub.status.idle":"2022-05-04T04:09:23.867699Z","shell.execute_reply.started":"2022-05-04T04:09:23.863941Z","shell.execute_reply":"2022-05-04T04:09:23.866993Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Train Model Function","metadata":{"id":"EHGjC_Wlgphj"}},{"cell_type":"code","source":"def train(\n    model,\n    loss_fn,\n    optimizer,\n    scheduler,\n    device,\n    data_loader,\n    n_examples\n):\n    model = model.train() # Setting Model in training mode\n\n    losses = []\n    correct_predictions = 0\n\n    for d in data_loader:\n        input_ids = d['input_ids'].to(device)  # [16, 512]\n        attention_mask = d['attention_mask'].to(device)  # [16, 512]\n        targets = d['spam'].to(device)  # [16]\n\n        # Forward Propogation\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        ) # [16, 3]\n        \n#         print(\"outputs\", outputs.argmax(dim=1))\n#         print('targets', targets)\n        \n\n        # Calculating Loss\n        loss = loss_fn(outputs, targets)\n\n        _, preds = torch.max(outputs, dim=1)\n\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n        \n        # Backward Propogation\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Clipping Gradient (Exploding Gradient Problem)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad() # Resetting gradients\n\n    train_acc = correct_predictions.double() / n_examples\n    train_loss = np.mean(losses)\n    \n    return train_acc, train_loss\n","metadata":{"id":"7sad0YiJRVjH","execution":{"iopub.status.busy":"2022-05-04T04:09:23.868963Z","iopub.execute_input":"2022-05-04T04:09:23.869686Z","iopub.status.idle":"2022-05-04T04:09:23.879476Z","shell.execute_reply.started":"2022-05-04T04:09:23.869648Z","shell.execute_reply":"2022-05-04T04:09:23.878679Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Validating Model Function","metadata":{"id":"rXYnwR0KguQ-"}},{"cell_type":"code","source":"def evaluate_model(\n    model,\n    loss_fn,\n    device,\n    data_loader,\n    n_examples   \n):\n    model = model.eval() # Setting Model in evaluation mode\n\n    losses = []\n    correct_predictions = 0\n\n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d['input_ids'].to(device)  # [16, 512]\n            attention_mask = d['attention_mask'].to(device)  # [16, 512]\n            targets = d['spam'].to(device)  # [16]\n\n            # Forward Propogation\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            ) # [16, 3]\n\n            # Calculating Loss\n            loss = loss_fn(outputs, targets)\n\n            _, preds = torch.max(outputs, dim=1)\n\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n        \n    train_acc = correct_predictions.double() / n_examples\n    train_loss = np.mean(losses)\n\n    return train_acc, train_loss\n","metadata":{"id":"G9PtqPEFenkA","execution":{"iopub.status.busy":"2022-05-04T04:09:23.882598Z","iopub.execute_input":"2022-05-04T04:09:23.882862Z","iopub.status.idle":"2022-05-04T04:09:23.890398Z","shell.execute_reply.started":"2022-05-04T04:09:23.882831Z","shell.execute_reply":"2022-05-04T04:09:23.889587Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model","metadata":{"id":"tABNoeFUg1iW"}},{"cell_type":"code","source":"%%time\n\n\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\n    print('-' * 10)\n\n    train_acc, train_loss = train(\n        model,\n        loss_fn,\n        optimizer,\n        scheduler,\n        device,\n        train_data_loader,\n        len(df_train)\n    )\n\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n\n    val_acc, val_loss = evaluate_model(\n        model,\n        loss_fn,\n        device,\n        val_data_loader,\n        len(df_val)\n    )\n\n    print(f'Validation loss {val_loss} accuracy {val_acc}')\n    print()\n\n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n\n    if val_acc > best_accuracy:\n        torch.save(model.state_dict(), 'best_model_state.bin')\n        best_accuracy = val_acc\n","metadata":{"id":"gN6kZep2aAsY","outputId":"b3c27913-d0bf-4031-9b68-3d49d9682159","execution":{"iopub.status.busy":"2022-05-04T04:09:23.891787Z","iopub.execute_input":"2022-05-04T04:09:23.892038Z","iopub.status.idle":"2022-05-04T04:12:20.005093Z","shell.execute_reply.started":"2022-05-04T04:09:23.892006Z","shell.execute_reply":"2022-05-04T04:12:20.004158Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating the Model Performance","metadata":{"id":"o4Yoe_oX40bi"}},{"cell_type":"code","source":"test_acc, _ = evaluate_model(\n    model,\n    loss_fn,\n    device,\n    test_data_loader,\n    len(df_test)\n)\ntest_acc.item()","metadata":{"id":"xs-xwmWnv0Zz","outputId":"525c8c3b-7a76-4665-da28-27f1d5c7a123","execution":{"iopub.status.busy":"2022-05-04T04:12:20.006984Z","iopub.execute_input":"2022-05-04T04:12:20.007278Z","iopub.status.idle":"2022-05-04T04:12:22.430125Z","shell.execute_reply.started":"2022-05-04T04:12:20.007238Z","shell.execute_reply":"2022-05-04T04:12:22.429346Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 7))\n\ntrain_acc_fig = torch.stack(history['train_acc'])\nval_acc_fig = torch.stack(history['val_acc'])\n\nplt.plot(train_acc_fig.cpu(), label='train accuracy')\nplt.plot(val_acc_fig.cpu(), label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\ny_start, y_end = 0.8, 1\nplt.ylim([y_start, y_end])","metadata":{"id":"JStEr4A9xI0K","outputId":"f7abd749-5ac4-442b-d2e5-4659dfc2e7aa","execution":{"iopub.status.busy":"2022-05-04T04:18:00.716844Z","iopub.execute_input":"2022-05-04T04:18:00.717124Z","iopub.status.idle":"2022-05-04T04:18:00.935930Z","shell.execute_reply.started":"2022-05-04T04:18:00.717096Z","shell.execute_reply":"2022-05-04T04:18:00.935247Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def get_predictions(\n    model, data_loader\n):\n    model = model.eval()\n\n    msgs = []\n    predictions = []\n    predictions_probs = []\n    real_values = []\n\n    with torch.no_grad():\n        for d in data_loader:\n            msg = d['msg']\n            input_ids = d['input_ids'].to(device)\n            attention_masks = d['attention_mask'].to(device)\n            spam = d['spam'].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_masks\n            )\n\n            _, preds = torch.max(outputs, dim=1)\n\n            probs = torch.nn.functional.softmax(outputs, dim=1)\n\n            msgs.extend(msg)\n            predictions.extend(preds)\n            predictions_probs.extend(probs)\n            real_values.extend(spam)\n    predictions = torch.stack(predictions).cpu()\n    predictions_probs = torch.stack(predictions_probs).cpu()\n    real_values = torch.stack(real_values).cpu()\n    return msgs, predictions, predictions_probs, real_values","metadata":{"id":"jxfjEVbVzhef","execution":{"iopub.status.busy":"2022-05-04T04:18:18.120324Z","iopub.execute_input":"2022-05-04T04:18:18.120883Z","iopub.status.idle":"2022-05-04T04:18:18.131834Z","shell.execute_reply.started":"2022-05-04T04:18:18.120844Z","shell.execute_reply":"2022-05-04T04:18:18.131143Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"y_msgs, y_pred, y_pred_probs, y_test = get_predictions(\n  model,\n  test_data_loader\n)","metadata":{"id":"qCxXj-3F258K","execution":{"iopub.status.busy":"2022-05-04T04:18:21.816934Z","iopub.execute_input":"2022-05-04T04:18:21.817190Z","iopub.status.idle":"2022-05-04T04:18:25.589699Z","shell.execute_reply.started":"2022-05-04T04:18:21.817162Z","shell.execute_reply":"2022-05-04T04:18:25.588811Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Creating Final Classification Report","metadata":{"id":"5gegGnUJ5tzp"}},{"cell_type":"code","source":"def create_classification_report(Y_test, Y_pred):\n    print('--------Classification Report---------\\n')\n    accuracy = accuracy_score(Y_test, Y_pred)\n    f1 = f1_score(Y_test, Y_pred)\n    precision = precision_score(Y_test, Y_pred)\n    recall = recall_score(Y_test, Y_pred)\n    roc_auc = roc_auc_score(Y_test, Y_pred)\n    metrices = [accuracy, f1, precision, recall, roc_auc]\n    scores = pd.DataFrame(pd.Series(metrices).values, index=['accuracy', 'f1-score', 'precision', 'recall', 'roc auc score'], columns=['score'])\n    print(scores)\n    print('\\n--------Plotting Confusion Matrix---------')\n    sns.heatmap(confusion_matrix(Y_test, Y_pred), annot=True, cmap='RdYlGn_r', annot_kws={'size': 16})\n    return scores","metadata":{"id":"Ck66KbYq3Ggq","execution":{"iopub.status.busy":"2022-05-04T04:18:27.576286Z","iopub.execute_input":"2022-05-04T04:18:27.576902Z","iopub.status.idle":"2022-05-04T04:18:27.583861Z","shell.execute_reply.started":"2022-05-04T04:18:27.576856Z","shell.execute_reply":"2022-05-04T04:18:27.583116Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"create_classification_report(y_test, y_pred)","metadata":{"id":"fOUdUgGM37r4","outputId":"8143d1a4-0691-4045-b9a7-3e1c2b615cc2","execution":{"iopub.status.busy":"2022-05-04T04:18:29.670322Z","iopub.execute_input":"2022-05-04T04:18:29.670801Z","iopub.status.idle":"2022-05-04T04:18:29.888181Z","shell.execute_reply.started":"2022-05-04T04:18:29.670759Z","shell.execute_reply":"2022-05-04T04:18:29.887490Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'cnn.pt')","metadata":{"id":"G_yenye14IKI","execution":{"iopub.status.busy":"2022-05-04T04:18:40.549052Z","iopub.execute_input":"2022-05-04T04:18:40.549318Z","iopub.status.idle":"2022-05-04T04:18:40.588719Z","shell.execute_reply.started":"2022-05-04T04:18:40.549288Z","shell.execute_reply":"2022-05-04T04:18:40.588018Z"},"trusted":true},"execution_count":34,"outputs":[]}]}